{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-776bdcdaa31aa0dd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Project 2: NYC Taxi Rides\n",
    "# Part 4:  Feature Engineering and Model Fitting\n",
    "\n",
    "In this final part of the project, you will finally build a regression model that attempts to predict the duration of a taxi ride from all other available information.\n",
    "\n",
    "You will build this model using a processing pipeline and submit your results to Kaggle. We will first walk you through a generic example using the data we saved from Part 1. Please carefully follow these steps as you will need to repeat this for your final model. After, we give you free reign and let you decide how you want to define your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T22:53:05.666930Z",
     "start_time": "2018-03-20T22:53:03.475900Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91e2a5cbad6e67c3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f4b545c2be61fe3c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Training and Validation\n",
    "\n",
    "The following code loads the training and validation data from part 1 into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec99abaff54cdd7c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data. \n",
    "data_file = Path(\"./\", \"cleaned_data.hdf\")\n",
    "train_df = pd.read_hdf(data_file, \"train\")\n",
    "val_df = pd.read_hdf(data_file, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28aff643fb4e8794",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Testing\n",
    "Here we load our testing data on which we will evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44d123e5bf4c04a4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./proj2_test_data.csv\")\n",
    "test_df['tpep_pickup_datetime'] = pd.to_datetime(test_df['tpep_pickup_datetime'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46e155fe7ae16e6c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d441ceef9b7f4e0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Modeling\n",
    "\n",
    "We've finally gotten to a point where we can specify a simple model. Remember that we will be fitting our model on the training set we created in part 1. We will use our validation set to evaluate how well our model might perform on future data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3725d1930850468b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Reusable Pipeline\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, this should be sufficient motivation to abstract parts of our code into reusable functions/methods.  We will now encapsulate our entire pipeline into a single function `process_data_gm`.  gm is shorthand for \"guided model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0627b259f25d7b70",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Copied from part 2\n",
    "def haversine(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute haversine distance\n",
    "    \"\"\"\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    average_earth_radius = 6371\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * average_earth_radius * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "# Copied from part 2\n",
    "def manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute Manhattan distance\n",
    "    \"\"\"\n",
    "    a = haversine(lat1, lng1, lat1, lng2)\n",
    "    b = haversine(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "# Copied from part 2\n",
    "def bearing(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute the bearing, or angle, from (lat1, lng1) to (lat2, lng2).\n",
    "    A bearing of 0 refers to a NORTH orientation.\n",
    "    \"\"\"\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "# Copied from part 2\n",
    "def add_time_columns(df):\n",
    "    \"\"\"\n",
    "    Add temporal features to df\n",
    "    \"\"\"\n",
    "    df.is_copy = False # propogate write to original dataframe\n",
    "    df.loc[:, 'month'] = df['tpep_pickup_datetime'].dt.month\n",
    "    df.loc[:, 'week_of_year'] = df['tpep_pickup_datetime'].dt.weekofyear\n",
    "    df.loc[:, 'day_of_month'] = df['tpep_pickup_datetime'].dt.day\n",
    "    df.loc[:, 'day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "    df.loc[:, 'hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df.loc[:, 'week_hour'] = df['tpep_pickup_datetime'].dt.weekday * 24 + df['hour']\n",
    "    return df\n",
    "\n",
    "# Copied from part 2\n",
    "def add_distance_columns(df):\n",
    "    \"\"\"\n",
    "    Add distance features to df\n",
    "    \"\"\"\n",
    "    df.is_copy = False # propogate write to original dataframe\n",
    "    df.loc[:, 'manhattan'] = manhattan_distance(lat1=df['pickup_latitude'],\n",
    "                                                lng1=df['pickup_longitude'],\n",
    "                                                lat2=df['dropoff_latitude'],\n",
    "                                                lng2=df['dropoff_longitude'])\n",
    "\n",
    "    df.loc[:, 'bearing'] = bearing(lat1=df['pickup_latitude'],\n",
    "                                   lng1=df['pickup_longitude'],\n",
    "                                   lat2=df['dropoff_latitude'],\n",
    "                                   lng2=df['dropoff_longitude'])\n",
    "    df.loc[:, 'haversine'] = haversine(lat1=df['pickup_latitude'],\n",
    "                                   lng1=df['pickup_longitude'],\n",
    "                                   lat2=df['dropoff_latitude'],\n",
    "                                   lng2=df['dropoff_longitude'])\n",
    "    return df\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    return data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-507f8020b5b9a835",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def process_data_gm1(data, test=False):\n",
    "    X = (\n",
    "        data\n",
    "        \n",
    "        # Transform data\n",
    "        .pipe(add_time_columns)\n",
    "        .pipe(add_distance_columns)\n",
    "        \n",
    "        .pipe(select_columns,        \n",
    "              'pickup_longitude',  \n",
    "              'pickup_latitude',   \n",
    "              'dropoff_longitude', \n",
    "              'dropoff_latitude',\n",
    "              'manhattan',\n",
    "             )\n",
    "    )\n",
    "    if test:\n",
    "        y = None\n",
    "    else:\n",
    "        y = data['duration']\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a3e4e0d97a10e09",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We will use our pipeline defined above to pre-process our training and test data in exactly the same way. Our functions make this relatively easy to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9a66cd4aafc3d03",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train, y_train = process_data_gm1(train_df)\n",
    "X_val, y_val = process_data_gm1(val_df)\n",
    "guided_model_1 = lm.LinearRegression(fit_intercept=True)\n",
    "guided_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = guided_model_1.predict(X_train)\n",
    "y_val_pred = guided_model_1.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ce124a1c3d16212",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Here, `y_val` are the correct durations for each ride, and `y_val_pred` are the predicted durations based on the 7 features above (`vendorID`, `passenger_count`, `pickup_longitude`, `pickup_latitude`, `dropoff_longitude`, `dropoff_latitude`, `manhattan`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b31246d46b057685",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 600 <= np.median(y_train_pred) <= 700\n",
    "assert 600 <= np.median(y_val_pred) <= 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ce43378a0326e03",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The resulting model really is a linear model just like we saw in class, i.e. the predictions are simply generated by the product $\\Phi\\theta$. For example, the line of code below generates a prediction for $x_1$ by computing $\\phi_1^T\\theta$. Here `guided_model_1.coef_` is $\\theta$ and `X_train.iloc[0, :]` is $\\phi_1$.\n",
    "\n",
    "Note that unlike in class, here the dummy intercept term is not included in $\\Phi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a486bf8f36567ef8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.iloc[0, :].dot(guided_model_1.coef_) + guided_model_1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49c8840a2ad44c8d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We see that this prediction is exactly the same (except for possible floating point error) as generated by the `predict` function, which simply computes the product $\\Phi\\theta$, yielding predictions for every input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8de12c4814aefa25",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd7b951877e62489",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In this assignment, we will use Mean Absolute Error (MAE), a.k.a. mean L1 loss, to measure the quality of our models.  As a reminder, this quantity is defined as:\n",
    "\n",
    "$$\n",
    "MAE =\\frac{1}{n}\\sum_{i}  | y_i -\\hat{y_i}|\n",
    "$$\n",
    "\n",
    "Why may we want to use the MAE as a metric, as opposed to Mean Squared Error (MSE)? Using our domain knowledge that most rides are short in duration (median is roughly 600 seconds), we know that MSE is susceptible to outliers. Given that some of the outliers in our dataset are quite extreme, it is probably better to optimize for the majority of rides rather than for the outliers. You may want to remove some of these outliers later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a710fd055e77566a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def mae(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculates MAE from actual and predicted values\n",
    "    Input:\n",
    "      actual (1D array-like): vector of actual values\n",
    "      predicted (1D array-like): vector of predicted/fitted values\n",
    "    Output:\n",
    "      a float, the MAE\n",
    "    \"\"\"\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a00a472b680ffd30",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 200 <= mae(y_val_pred, y_val) <= 300\n",
    "print(\"Validation Error: \", mae(y_val_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9b97bc51faaf9d24",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Side note: scikit-learn also has tools to compute mean absolute error (`sklearn.metrics.mean_absolute_error`). In fact, most metrics that we have discussed in this class can be found as part of the [`sklearn.metrics` module](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics). Some of these may come in handy as part of your feature engineering!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02af4613f224d0b8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Visualizing Error\n",
    "You should be getting between 200 and 300 MAE, which means your model was off by roughly 3-5 minutes on trips of average length 12 minutes. This is fairly decent performance given that our basic model uses only using the pickup/dropoff latitude and manhattan distance of the trip. 3-5 minutes may seem like a lot for a trip of 12 minutes, but keep in mind that this is the *average* error. This metric is susceptible to extreme outliers, which exist in our dataset. \n",
    "\n",
    "Now we will visualize the residual for the validation set. We will plot the following:\n",
    "\n",
    "1. Distribution of residuals\n",
    "2. Average residual grouping by ride duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6e3b30f7693966b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of residuals\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.distplot(np.abs(y_val - y_val_pred))\n",
    "plt.xlabel('residual')\n",
    "plt.title('distribution of residuals');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69e4e7c6638615ac",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Average residual grouping by ride duration\n",
    "val_residual = X_val.copy()\n",
    "val_residual['duration'] = y_val\n",
    "val_residual['rounded_duration'] = np.around(y_val, -2)\n",
    "val_residual['residual'] = np.abs(y_val - y_val_pred)\n",
    "tmp = val_residual.groupby('rounded_duration').mean()\n",
    "plt.figure(figsize=(8,4))\n",
    "tmp['residual'].plot()\n",
    "plt.ylabel('average residual')\n",
    "plt.title('average residual by ride duration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db93e20cec0d6aff",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the first visualization, we see that most of the residuals are centered around 250 seconds ~ 4 minutes. There is a minor right tail, suggesting that we are still unable to accurately fit some outliers in our data. The second visualization also suggests this, as we see the average residual increasing as a somewhat linear function of duration. But given that our average ride duration is roughly 600-700 seconds, it seems that we are indeed optimizing for the average ride because the residuals are smallest around 600-700. \n",
    "\n",
    "Keep this in mind when creating your final model! Visualizing the error is a powerful tool and may help diagnose shortcomings of your model. Let's go ahead and submit to kaggle, although your error on the test set may be higher than 300. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0398ecf597b3cf59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Submission to Kaggle\n",
    "\n",
    "The following code will write your predictions on the test dataset to a CSV, which you can submit to Kaggle. You may need to modify it to suit your needs, but we recommend you make a copy and preserve the original function.\n",
    "\n",
    "Remember that if you've performed transformations or featurization on the training data, you must also perform the same transformations on the test data in order to make predictions. For example, if you've created features for the columns `pickup_datetime` or `pickup_latitude` on the training data, you must also extract the same features in order to use scikit-learn's `.predict(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46e29e97c3760a86",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def generate_submission(test, predictions, force=False):\n",
    "    if force:\n",
    "        if not os.path.isdir(\"submissions\"):\n",
    "            os.mkdir(\"submissions\")\n",
    "        submission_df = pd.DataFrame({\n",
    "            \"id\": test_df.index.values, \n",
    "            \"duration\": predictions,\n",
    "        },\n",
    "            columns=['id', 'duration'])\n",
    "\n",
    "        timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "\n",
    "        submission_df.to_csv(f'submissions/submission_{timestamp}.csv', index=False)\n",
    "\n",
    "        print(f'Created a CSV file: submission_{timestamp}.csv')\n",
    "        print('You may now upload this CSV file to Kaggle for scoring.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c77a057c8897ad5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_test, _ = process_data_gm1(test_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T23:29:22.604349Z",
     "start_time": "2018-03-18T23:29:22.265985Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4d56cb38e5d6ad5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert list(X_train.columns) == list(X_test.columns), \"Different columns or different column ordering\"\n",
    "submission_predictions = (guided_model_1\n",
    "                          .fit(X_train, y_train)\n",
    "                          .predict(X_test))\n",
    "submission_predictions = submission_predictions.astype(int)\n",
    "submission_predictions[submission_predictions < 0] = 0\n",
    "generate_submission(test_df, submission_predictions, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e4fef935fcd3d1f",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check your submission\n",
    "assert isinstance(submission_predictions, np.ndarray), \"Submission not an array\"\n",
    "assert all(submission_predictions >= 0), \"Duration must be non-negative\"\n",
    "assert issubclass(submission_predictions.dtype.type, np.integer), \"Seconds must be integers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-841ea29e54b5d9b2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "Now it's your turn! Draw upon everything you have learned this semester to find the best features to help your model accurately predict the duration of a taxi ride.\n",
    "\n",
    "You may use whatever method you prefer in order to create features. You may use features that we created and features that you discovered yourself from any of the 2 datasets. However, we want to make it fair to students who are seeing these techniques for the first time. As such, you are only allowed regression models and their regularized forms. This means no random forest, k-nearest-neighbors, neural nets, etc.\n",
    "\n",
    "**Here are some ideas to improve your model:**\n",
    "- **Data selection**: January 2016 was an odd month for taxi rides due to the blizzard. Would it help to select training data differently?\n",
    "- **Data cleaning**: Try cleaning your data in different ways. In particular, consider how to handle outliers. \n",
    "- **Better features**: Explore the 2 datasets and find what features are most helpful. Utilize external datasets to improve your accuracy. \n",
    "- **Regularization**: Try different forms of regularization to avoid fitting to the training set. Recall that `Ridge` and `Lasso` are the names of the classes in `sklearn.linear_model` that combine `LinearRegression` with regularization techniques.\n",
    "- **Model selection**: You can adjust parameters of your model (e.g., the regularization parameter) to achieve higher accuracy. [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) may be helpful.\n",
    "- **Validation**: Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n",
    "\n",
    "There's many things you could try that could help your model. We have only suggested a few. Be creative and innovative! Please use `proj2_extras.ipynb` for all of your extraneous work. Note that you will be submitting `proj2_extras.ipynb` and we will be grading it. Please properly comment and format this notebook!\n",
    "\n",
    "Once you are satisfied with your results, answer the questions in the Deliverables section. You may want to read this section in advance so you have an idea of what we're looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-926dd79601c9e5bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28fcb99d211b6d14",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Feature/Model Selection Process\n",
    "\n",
    "Let's first look at selection of better features. In this following cell, describe the process of choosing good features to improve your model. You should use at least 3-4 sentences each to address the follow questions. Backup your responses with graphs supporting your claim (you can save figures and load them, no need to add the plotting code here). Use these questions to concisely summarize all of your extra work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a\n",
    "How did you find better features for your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1a-answer",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1a_answer = r\"\"\"\n",
    "For the training data, I dropped the blizzard data in order to avoid outliers. Also, there are many missing data \n",
    "in the training set, I convert nan value in `latitude` and `longtitude` value to median value in preprocessing.\n",
    "There are also outliers in `fare_amount` and `total_amount`, and I also replaced outliers by median value.\n",
    "\"\"\"\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "What did you try that worked / didn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1b-answer",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1b_answer = r\"\"\"\n",
    "I contrasted different features and their correlation to `duration`, carefully selecting relevant features.\n",
    "I choose Ridge regression and select best regularization parameter for the model in order to avoid overfitting.\n",
    "During the selection of parameter-tuning, I use 5-fold cross-validation to select the best parameter.\n",
    "\n",
    "However, some features are not relevant to the prediction, like `VendorID`, `month` etc. Also, from part 2 we\n",
    "create too many features about date and time. There are redundancy here so we need to drop some.\n",
    "\"\"\"\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "What was surprising in your search for good features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1c-answer",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1c_answer = r\"\"\"\n",
    "Simply correcting missing data helps a lot on improving the model performance. However, adding more features\n",
    "and hyperparameter tuning do little help.\n",
    "\"\"\"\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Just as in the guided model above, you should encapsulate as much of your workflow into functions as possible.  Define `process_data_fm` and `final model` in the cell below.  In order to calculate your final model's MAE, we will run the code in the cell after that.\n",
    "\n",
    "**Note:** You *MUST* name the model you wish to be evaluated on `final_model`. This is what we will be using to generate your predictions. We will take the state of `final_model` right after executing the cell below and run the following code:\n",
    "\n",
    "```\n",
    "# Load in test_df, solutions\n",
    "X_test, _ = process_data_fm(test_df, True)\n",
    "submission_predictions = final_model.predict(X_test)\n",
    "# Generate score for autograding\n",
    "```\n",
    "\n",
    "We encourage you to conduct all of your exploratory work in `proj2_extras.ipynb`, which will be graded for 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-answer",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def process_data_fm(data, test=False):\n",
    "    # Put your final pipeline here\n",
    "    ...\n",
    "    \n",
    "final_model = ... # Define your final model here, feel free to try other forms of regression\n",
    "# final_model.fit(...)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def remove_outliers(data, outlier_col, test=False):\n",
    "    if test:\n",
    "        return data\n",
    "    if outlier_col == \"duration\":\n",
    "        return data[(data['duration'] < np.percentile(data['duration'], 80)) & (data['duration'] > np.percentile(data['duration'], 20))]\n",
    "    elif outlier_col == \"manhattan\":\n",
    "        return data[(data['manhattan'] < np.percentile(data['manhattan'], 80)) & (data['manhattan'] > np.percentile(data['manhattan'], 20))]\n",
    "    elif outlier_col == \"haversine\":\n",
    "        return data[(data['haversine'] < np.percentile(data['haversine'], 80)) & (data['haversine'] > np.percentile(data['haversine'], 20))]\n",
    "    elif outlier_col == \"bearing\":\n",
    "        return data[(data['bearing'] < np.percentile(data['bearing'], 80)) & (data['bearing'] > np.percentile(data['bearing'], 20))]\n",
    "\n",
    "def process_data_fm(data, test=False):\n",
    "    if test:\n",
    "        X = (\n",
    "            data\n",
    "\n",
    "            # Transform data\n",
    "            .pipe(add_time_columns)\n",
    "            .pipe(add_distance_columns)\n",
    "\n",
    "            .pipe(select_columns, \n",
    "                  'VendorID',        \n",
    "                  'passenger_count',            \n",
    "                  'pickup_longitude',  \n",
    "                  'pickup_latitude',   \n",
    "                  'dropoff_longitude', \n",
    "                  'dropoff_latitude',\n",
    "                  'manhattan',\n",
    "                  'bearing',\n",
    "                  'haversine',\n",
    "                  'hour',\n",
    "                  'week_hour',\n",
    "                 )\n",
    "        )\n",
    "        return X, None\n",
    "    data = (\n",
    "        data\n",
    "        # Remove temporal outliers\n",
    "        .pipe(remove_outliers, 'duration', test)\n",
    "        \n",
    "        # Transform data\n",
    "        .pipe(add_time_columns)\n",
    "        .pipe(add_distance_columns)\n",
    "        \n",
    "        # Remove spatial outliers\n",
    "        .pipe(remove_outliers, 'manhattan', test)\n",
    "        .pipe(remove_outliers, 'bearing', test)\n",
    "        .pipe(remove_outliers, 'haversine', test)\n",
    "        \n",
    "        .pipe(select_columns, \n",
    "              'VendorID',        \n",
    "              'passenger_count',            \n",
    "              'pickup_longitude',  \n",
    "              'pickup_latitude',   \n",
    "              'dropoff_longitude', \n",
    "              'dropoff_latitude',\n",
    "              'manhattan',\n",
    "              'duration',\n",
    "              'bearing',\n",
    "              'haversine',\n",
    "              'hour',\n",
    "              'week_hour',\n",
    "             )\n",
    "    ) \n",
    "\n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['duration'], axis = 1)\n",
    "    y = data['duration']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = process_data_fm(train_df)\n",
    "X_val, y_val = process_data_fm(val_df)\n",
    "final_model = lm.Ridge(fit_intercept=True)\n",
    "\n",
    "\n",
    "final_model.fit(X_train, y_train);\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change this cell\n",
    "X_test, _ = process_data_fm(test_df, True)\n",
    "final_predictions = final_model.predict(X_test)\n",
    "final_predictions = final_predictions.astype(int)\n",
    "generate_submission(test_df, final_predictions, False) # Change to true to generate prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-adae1031103d7053",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3\n",
    "The following hidden cells will test your model on the test set. Please do not delete any of them if you want credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-49787d08aa5b0d72",
     "locked": true,
     "points": 0,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TOUCH\n",
    "### BEGIN HIDDEN TESTS\n",
    "solutions_df = pd.read_csv(\"/srv/db/proj2_test_solutions.csv\")\n",
    "solutions_df['tpep_dropoff_datetime'] = pd.to_datetime(solutions_df['tpep_dropoff_datetime'])\n",
    "solutions_df['tpep_pickup_datetime'] = pd.to_datetime(solutions_df['tpep_pickup_datetime'])\n",
    "solutions_df['duration'] = solutions_df['tpep_dropoff_datetime'] - solutions_df['tpep_pickup_datetime']\n",
    "solutions_df['duration'] = solutions_df['duration'].dt.total_seconds()\n",
    "\n",
    "y_true = solutions_df['duration']\n",
    "y_true = y_true.astype(int)\n",
    "\n",
    "X_test, _ = process_data_fm(test_df, True)\n",
    "submission_predictions = final_model.predict(X_test)\n",
    "submission_predictions = submission_predictions.astype(int)\n",
    "submission_predictions[submission_predictions < np.percentile(submission_predictions, 5)] = np.percentile(submission_predictions, 5)\n",
    "submission_predictions[submission_predictions > np.percentile(submission_predictions, 95)] = np.percentile(submission_predictions, 95)\n",
    "score = mae(submission_predictions, y_true)\n",
    "print(\"Score: \", score)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd20db43e21281c2",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# NOH\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score < np.inf\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dde1980abb5265eb",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# STAHP\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 1000\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4720d6f913f2e2a8",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# NO MOLESTE\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 950\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-becfc4e39f8d613d",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# VA-T'EN\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 900\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-66c75927b3162384",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# NEIN\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 850\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-480ee1c73e5aeed2",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# PLSNO\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 800\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5c13060e51df5fbf",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# THIS SPACE IS NOT YOURS\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 750\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9594161a0c8ada1b",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TAWDEETAW\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 700\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7ff15da448905075",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# MAU LEN\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 650\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5799ae0e2e02e4ea",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ALMOST\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 600\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4e8f93c8d961fdc3",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TO\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 550\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cb843d9e9defdb3f",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# THE\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 500\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a83a8dbeab2377b8",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# END\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 450\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c11ba085e96a4d43",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hmph\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 400\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d83490b23ffd0d29",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Good riddance\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert score <= 350\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c37f9560ddca0dd2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "generate_submission(test_df, submission_predictions, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac585a9fd1711d23",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "This should be the format of your CSV file.  \n",
    "Unix-users can verify it running `!head submission_{datetime}.csv` in a jupyter notebook cell.\n",
    "![sample_submission_format](figs/sample_submission_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f5d963bfa6acfdf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Kaggle link: https://www.kaggle.com/t/f8b3c6acc3a045cab152060a5bc79670"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
